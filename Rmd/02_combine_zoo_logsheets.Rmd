---
title: "Combine Zooplankton Logsheet"
author: "Sebastian DiGeronimo"
date: '2022-07-08'
output: html_document
---

# Load Packages
This loads any packages that are not contained in the .Rprofile.
```{r setup}
librarian::shelf(
    readxl, hablar, worrms, ggforce, geosphere, vroom, plotly,
    quiet = TRUE
    )

# Load helper functions if not already
source(here("scripts", "attach_funcs.R"))
func_attach()
rm(func_attach)
```


# Load cruise metadata files from Box `imars_mbon_cruises/years/` or elsewhere


1. Parse all file paths
- Will ignore files with `~$` in front because these are usually temporary files that are opened
2. Remove files that would not contain zooplankton metadata
3. Loop through each file and look for sheet with `zooplankton` in the name 


```{r read-sheets, include=FALSE}
if (!exists("main_cloud_dir")) main_cloud_dir <- rstudioapi::selectDirectory()

# select all cruise files
metadata_paths <-
  main_cloud_dir %>%
  dir_ls(type = "directory") %>%
  dir_ls(regexp = "metadata", recurse = 1) %>%
  dir_ls(regexp = "\\.xlsx$") %T>% 
  {
    cat("All `xlsx` files\n---\n\n")
    basename(.) %>%
    sort() %>%
    print()    
  } %>%
  
  # filter out non-metadata files
  str_subset(
     paste(
    "(?i)ignore|~|filtA|All_cruise|BB3|Digna|Schedule|Kelble|apad|cdom",
    "cruisetrack|noaa|sample_id_|zooplankton|collected|net_tow|edna",
    "creation_blank|core|mwreu_",
       sep = "|"), 
    negate = TRUE) %T>% 
  {
    cat("\n\n---\nFiltered files\n---\n\n")
    basename(.) %>%
    print()    
  }
```


```{r read-sheets, include=FALSE}
meta_skips <-
  metadata_paths %>%
  tibble(file = .) %>%
  mutate(
    base      = basename(file),
    cruise_id = str_extract(file, "(WS|SV|HG|H|WB)\\d{4,5}"),
    sheets =
    # read all files for sheet names that match `zooplankton`
      map_chr(
        .x = file,
        \(.x) {
          cli_alert_info("Reading file: {basename(.x)}")
          sht_all <- readxl::excel_sheets(.x) 
          sht <- str_subset(sht_all, "(?i)zooplankton", negate = FALSE)

          if (is_empty(sht)) sht <- NA_character_

          sht
        }
      )
  ) %>%
  print() %>%
  filter(!is.na(sheets)) %>%
  mutate(
    skips =
      map2_int(
        .x = file,
        .y = sheets,
        # find row number to start zooplankton metadata
        function(.x, .y) {
          cat(basename(.x), "\n")

          skips <- 
            readxl::read_xlsx(
              .x,
              range        = cell_cols("A"),
              sheet        = .y,
              col_names    = FALSE,
              .name_repair = "unique_quiet"
            ) %>%
            pull(1) %>%
            str_which("(?i)zooplankton sampling")

          # if skips can't find a number, will make NA
          skips <- if_else(is_empty(skips), NA_integer_, skips)
          
          skips
        }
      )
  ) %T>%
  print()
```


# Load Logsheets


1. read spreadsheet
2. remove empty rows
3. remove column `formalin_vol_ml` as is not necessary
4. fill down for station, lat, lon, date and time
5. drop rows when flowmeter out is NA
6. if has column `local_time_est`, convert time to gmt
    - then rename `time_gmt`
7. convert `time_gmt` to a time object using `hms`
8. combine date and time to create date time column
9. if lat/lon are characters, convert to decimal degrees
10. convert tow_tow_min to minutes with decimals for seconds
12. check if data is output 

```{r load-logsheets}
meta <-
  meta_skips %>%
  # slice(1) %>%
  filter(!is.na(skips)) %>%
  mutate(
    data = pmap(
      .l = list(.x = file, .y = skips, .z = sheets, .c = cruise_id),
      function(.x, .y, .z, .c) {
        cli_alert_info(.c)

        # read sheets
        temp <-
          readxl::read_xlsx(
            .x,
            sheet = .z,
            skip = .y,
            .name_repair = janitor::make_clean_names,
            na = c("skip", "Did not collect", "not recorded", "na")
          ) %>%
          # remove rows that are fully empty
          janitor::remove_empty(which = "rows") %>%
          # remove formalin_vol_ml column
          select(-contains("formalin_vol_ml")) %>%
          
          # fill down if lat, lon, date, or time is not there
          tidyr::fill(contains(c("station", "lat", "lon", "date", "time"))) %>%

          # drop rows when flowmeter_out = NA
          drop_na(flowmeter_out) %>%
          mutate(
            across(
              contains("local_time_est"),
              \(.x) {
                # if have est time, convert to gmt/utc time
                x <-
                  tryCatch(
                    {
                      ymd_hms(.x, tz = "est") %>%
                        format(
                          format = "%H:%M:%S",
                          tz = "utc"
                        ) %>%
                        hms::as_hms()
                    },
                    warning = function(w) {
                      NA
                    },
                    error = function(e) {
                      NA
                    }
                  )
              }
            )
          ) %>%
          rename("time_gmt" = contains("local_time_est")) %>%
          
          mutate(
            # convert time if labeled as time_gmt if needed
            across(
              contains(c("time_gmt")),
              \(.x) {
                x <-
                  tryCatch(
                    {
                      hms::as_hms(
                        format(
                          .x,
                          format = "%H:%M:%S",
                          tz = "utc"
                        )
                      )
                    },
                    warning = function(w) {
                      NA
                    },
                    error = function(e) {
                      NA
                    }
                  )
              }
            ),

            # convert time_gmt to date_time if possible with date and time
            across(
              contains(c("time_gmt")),
              list(date_time = \(.x) {
                x <-
                  tryCatch(
                    {
                      ymd_hms(paste(date, .x), tz = "utc")
                    },
                    warning = function(w) {
                      NA_POSIXct_
                    },
                    error = function(e) {
                      NA_POSIXct_
                    }
                  )
              }),
              .names = "{.fn}"
            ),
            .after = 4
          )

        # convert lat_in and/or lon_in from deg minutes to decimal
        # degrees if type is str
        if (is.character(temp$lat_in) | is.character(temp$lon_in)) {
          message("Converting lat and lon into decimal degrees.\n")
          temp %<>%
            add_column(
              with(
                .,
                parzer::parse_lon_lat(lon_in, lat_in)
              ),
              .after = "lon_in"
            ) %>%
            select(-lon_in, -lat_in) %>%
            rename("lon_in" = lon, "lat_in" = lat)
        }

        # change name of x to notes if exists
        if (!is.null(temp)) temp <- rename(temp, any_of(c(notes = "x")))

        # check if can retype columns to chr, num, or date
        temp <- tryCatch(
          {
            temp <- hablar::retype(temp, -time_gmt)
          },
          error = function(e) {
            message("Doesn't have a time_gmt column. Returning as is.\n")
            temp
          }
        )

        # specify what to convert types to merge later
        temp <- hablar::convert(
          temp,
          chr(
            ship_speed_knots, split_size,
            station, mesh_size_um
          )
        )

        # if (str_detect(.c, "WS16207")) browser()
        if (is.POSIXct(temp$tow_time_min)) {
          temp <-
            temp %$%
            hms::as_hms(tow_time_min) %>%
            str_split(":", simplify = TRUE) %>%
            as_tibble() %>%
            mutate(
              across(c(V1, V2, V3), \(x) as.numeric(x)),
              time = V1 + V2 / 60
            ) %>%
            select(tow_time_min = time) %>%
            bind_cols(select(temp, -tow_time_min), .)
        }

        temp
      }
    ),
    # filter for sheets without any information
    data_exists =
      map(.x = data, ~ if_else(nrow(.x) > 0, 1, 0)) %>%
        unlist()
  ) %T>%
  print()

```




# Keep record of files that have no data because either didn't collect or didn't write down


```{r filter-no-data}
no_data <- filter(meta, data_exists == 0)

cli::cli_alert_danger("Cruise(s) with no data:")
cat_bullet(no_data$cruise_id)

no_data %>%
  pull(data)

# open files to check zooplankton
# map(
#   .x = no_data$file,
#   \(.x) {
#       shell.exec(.x)
#   }
# )

```
# Merge Metadata 

Merge all metadata sheets across all cruises when samples are taken

```{r merge-metadata}
meta_merg <- 
  meta %>%
  filter(data_exists > 0) %>%
  select(-data_exists) %>%
  unnest(data) %T>% 
  print()
```


# Add/Remove/Rename Columns

Remove:
- file
- sheets
- skips
- local_time_est

Modify:
- 

```{r filter-no-data}
meta_fix <-
  meta_merg %>%
  select(-sheets, -skips, -contains("local_time_est")) %>%
  rename(
    "ignore_distance_m" = distance_m, 
    "ignore_tow_speed"  = tow_speed
    ) %>%
  relocate(flowmeter_in, .before = flowmeter_out) %>%
  separate_rows(mesh_size_um, sep = "/") %>%
  mutate(
    mesh_size_um     = str_trim(mesh_size_um),
    mesh_size_um     = retype(mesh_size_um),
    ship_speed_knots = str_remove_all(ship_speed_knots, "~"),
    file             = tools::file_path_sans_ext(file),
    split_size       = map_dbl(split_size, 
      function(x) {
        out <- tryCatch(
          {
            eval(parse(text = x))
          },
          error = function(e) {
            NA_integer_
          }
        )
      }),
  ) %>%
  arrange(date) %>%
  mutate(
    .after = station,
    
    # add location ID as DarwinCore column name
    locationID = case_when(
      str_detect(station, "Mol") ~ "MR",
      str_detect(station, "Loo") ~ "LK",
      str_detect(station, "West") ~ "WS",
      str_detect(station, "9B") ~ "9B",
      .default = station
    ),
    
    # rename station to full name
    station = case_when(
      str_detect(locationID, "MR") ~ "Molasses Reef",
      str_detect(locationID, "LK") ~ "Looe Key (deep)",
      str_detect(locationID, "WS") ~ "Western Sambo",
      .default = locationID
    ),
    
    # Fix Latitude and Longitude
    # Some files had mixed up lat and lon and some have lon at a positive
    # decimal degree and should only be negative.
    lon_in = case_when(
      str_detect(locationID, "MR") ~ -80.38000,
      str_detect(locationID, "WS") ~ -81.71700,
      str_detect(locationID, "LK") ~ -81.41300,
      str_detect(locationID, "57") ~ -81.26500,
      str_detect(locationID, "54") ~ -81.15283,
      .default = lon_in
    ),
    lat_in = case_when(
      str_detect(locationID, "MR") ~ 25.01000,
      str_detect(locationID, "WS") ~ 24.47800,
      str_detect(locationID, "LK") ~ 24.53800,
      str_detect(locationID, "57") ~ 25.35167,
      str_detect(locationID, "54") ~ 25.34533,
      .default = lat_in
    )
  ) %T>% 
 print()
```

# Calculations

- net size
- net area
- distance
- tow speed (m/sec)
- volume filtered (m^3)

```{r calculations}
meta_calc <- 
  meta_fix %>%
  mutate(
    # Note: flowmeter is MF315
    net_size = # diameter in m
      case_when(
        mesh_size_um == 64 ~ 0.6,
        mesh_size_um == 200 ~ 0.5,
        mesh_size_um == 500 ~ 0.5
      ),
    net_area            = pi * (net_size / 2)^2, # m^2
    flowmeter_diff      = flowmeter_out - flowmeter_in,
    distance_m          = flowmeter_diff * inpeller_constant, # m
    tow_speed_m_sec     = distance_m / (tow_time_min * 60), # m s^-1
    volume_filt_cubic_m = net_area * distance_m, # m^3

  ) %>%
  relocate(flowmeter_diff, .after = flowmeter_out) %>%
  relocate(contains("ignore"), .after = last_col()) %>%
  relocate(date_time, date, time_gmt, .after = mesh_size_um) %T>% 
  print()
```




# Find Potiential Errors

```{r errors}
# volume filtered < 0 or > 500 
meta_calc %>%
  filter(volume_filt_cubic_m > 500 | volume_filt_cubic_m <= 0) %>%
  select(
    -c(file, net_size:tow_speed_m_sec, ship_speed_knots, inpeller_constant, 
       split_size, contains("ignore"))
    )
```


## Plot Volume Filtered

Plot data to find erroneous entries

```{r plots}
meta_calc %>% 
  filter(str_detect(locationID, "MR|LK|WS")) %>%
  ggplot(aes(x = date, y = volume_filt_cubic_m, color = locationID)) +
  geom_point() +
  facet_grid(cols = vars(locationID), rows = vars(mesh_size_um), scales = "free")


meta_calc %>% 
  filter(str_detect(locationID, "MR|LK|WS")) %>%
  ggplot(aes(x = date, y = volume_filt_cubic_m, color = locationID)) +
  geom_point() +
  facet_grid(cols = vars(locationID), rows = vars(mesh_size_um), scales = "free") +
  scale_y_continuous(limits = c(-100, 1200), expand = expansion())
    
# volume filt <= 0 or > 500   
meta_calc %>%
  filter(volume_filt_cubic_m <= 0 | volume_filt_cubic_m > 500) %T>%
  print() %>%
  ggplot(aes(x = date, y = volume_filt_cubic_m, color = locationID)) +
  geom_point() +
  facet_grid(cols = vars(locationID), rows = vars(mesh_size_um), scales = "free")  

# tow time vs vol filt
meta_calc %>% 
  filter(str_detect(locationID, "MR|LK|WS")) %>%
  ggplot(aes(x = tow_time_min, y = volume_filt_cubic_m, color = as.factor(year(date)))) +
  geom_point() +
  facet_grid(cols = vars(locationID), rows = vars(mesh_size_um), scales = "free") +
  # scale_y_continuous(limits = c(-100, 1200), expand = expansion()) +
  scale_x_continuous(limits = c(0, NA), expand = expansion(0, c(0, 1))) 

meta_calc %>% 
  filter(str_detect(locationID, "MR|LK|WS")) %>%
  ggplot(aes(x = tow_time_min, y = volume_filt_cubic_m, color = as.factor(year(date)))) +
  geom_point() +
  facet_grid(cols = vars(locationID), rows = vars(mesh_size_um), scales = "free") +
  scale_y_continuous(limits = c(-100, 1000), expand = expansion(0, c(0, 100))) +
  scale_x_continuous(limits = c(0, NA), expand = expansion(0, c(0, 1)), 
                     breaks = seq(0, 8)) 

```



# Save merged metadata

```{r save}
meta_final <-
  select(meta_calc, -file, "file" = base) %>%
  mutate(date = as_date(date))

overwrite <- FALSE
# overwrite <- TRUE

# ---- write metadata to file ----
save_csv(
  .data          = meta_final,        
  save_location  = here("data", "metadata", "cruise_logsheets"),
  save_name      = "meta_combined",
  overwrite      = overwrite,
  verbose        = TRUE,
  time_stamp_fmt = "%Y%m%d_%H%M%S",
  utf_8          = FALSE
)

# copy to cloud
if (FALSE) {
  here("data", "metadata", "cruise_logsheets") %>%
  dir_ls(regexp = "meta_combined") %>%
  last_mod() %>% 
  file_copy(
      here(cloud_dir, "cruise_logsheets", "meta_combined.csv"),
      overwrite = TRUE
  )
}

# for NOAA AOML
if (FALSE) {
  here("data", "metadata", "to_noaa") %>%
  dir_create()
    
  meta_final %>%
    select(-contains("ignore"), -file) %>%
    relocate(notes, .after = volume_filt_cubic_m) %>%
    openxlsx2::write_xlsx(
      .,
      here("data", "metadata", "to_noaa", glue("usf_imars_zooplankton_log_sheet_{Sys.Date()}.xlsx")),
      na.strings = "",
      overwrite = overwrite
    )
}
```




# # -------- #


# NOAA Written Logs Digitized Zooplankton Net Tows

File: `zooplankton_net_tows.xlsx`

A pdf from NOAA AOML with the original hand written logs was digitized by 
Lilly Verrill and Mia Poage in summer 2023.

This file contains:
- cruise_id
- date
- station
- net_size (i.e. mesh size)
- time
- time_zone (b/c was recorded in EDT)
- flowmeter_in	
- latitude	
- longitude	
- tow_time (as time and needs to be converted to number)
- flowmeter_out	
- notes



```{r}
noaa_zoo_pdf <-
  here(cloud_dir, "../miscellaneous_tasks") %>%
  dir_ls(regexp = "zooplankton_net_tows.xlsx") %>%
  str_subset("~\\$", negate = TRUE) %>%
  read_excel() %T>%
  print() %>%
  mutate(
    .before = time,
    time = str_remove(time, "\\d{4}-\\d{2}-\\d{2}\\s"),
    date_time =
      pmap(
        list(
          date,
          time,
          time_zone
        ),
        \(.date, .time, .timezone) {
          # print(.timezone)

          if (is.na(.timezone)) {
            return(lubridate::NA_POSIXct_)
          }
          .timezone <- if_else(.timezone == "EDT", "EST", .timezone)
          as_datetime(paste(.date, .time), tz = .timezone)
        }
      ),
  ) %>%
  unnest(date_time) %>%
  mutate(
    date      = as_date(date_time),
    time      = hms::as_hms(date_time),
    
    # lat/lon fix if has space
    longitude = paste(longitude, "W"),
    latitude  = parzer::parse_lat(latitude),
    longitude = parzer::parse_lon(longitude),
    
  ) %>%
  select(-time_zone) %>%
  relocate(date, .after = date_time) %>%
  mutate(
    tow_time2 = hms::as_hms(tow_time),
    tow_time2 = str_split(tow_time2, ":")
  ) %>%
  unnest_wider(tow_time2, names_sep = "_") %>%
  mutate(
    across(contains("tow_time2"), as.numeric),  
    tow_time = tow_time2_1 + tow_time2_2/ 60
  ) %>%
  select(-contains("tow_time2")) %T>% 
  print()

```

## Rename and Add Calculations to Digitized Zooplantkon Net Tow

Renaming columns:
New                Old
"mesh_size_um" = net_size
"tow_time_min" = tow_time
"locationID"   = station
"lon_in"       = longitude
"lat_in"       = latitude

Add Columns:
inpeller_constant
net_size (as the diameter of the net in meters)

Calculations:
net_area        = pi * (net_size/2)^2)
flowmeter_diff  = flow out - flow in
distance_m      = flowmeter_diff * inpeller_constant
tow_speed_m_sec = distance_m / (tow_time_min * 60)


```{r fix-noaa-digitized}
noaa_zoo_metadata <-
  noaa_zoo_pdf %>%
  rename(
    "mesh_size_um" = net_size,
    "tow_time_min" = tow_time,
    "locationID"   = station,
    "lon_in"       = longitude,
    "lat_in"       = latitude
  ) %>%
  mutate(
    inpeller_constant = 0.245,
    # Note: flowmeter is MF315
    net_size = # diameter in m
      case_when(
        mesh_size_um == 64 ~ 0.6,
        mesh_size_um == 200 ~ 0.5,
        mesh_size_um == 500 ~ 0.5
      ),
    net_area            = pi * (net_size / 2)^2, # m^2
    flowmeter_diff      = flowmeter_out - flowmeter_in,
    distance_m          = flowmeter_diff * inpeller_constant, # m
    tow_speed_m_sec     = distance_m / (tow_time_min * 60), # m s^-1
    volume_filt_cubic_m = net_area * distance_m, # m^3

    # Fix Latitude and Longitude
    # Some files had mixed up lat and lon and some have lon at a positive
    # decimal degree and should only be negative.
    lon_in = case_when(
      str_detect(locationID, "MR") ~ -80.38000,
      str_detect(locationID, "WS") ~ -81.71700,
      str_detect(locationID, "LK") ~ -81.41300,
      str_detect(locationID, "57") ~ -81.26500,
      str_detect(locationID, "54") ~ -81.15283,
      .default = lon_in
    ),
    lat_in = case_when(
      str_detect(locationID, "MR") ~ 25.01000,
      str_detect(locationID, "WS") ~ 24.47800,
      str_detect(locationID, "LK") ~ 24.53800,
      str_detect(locationID, "57") ~ 25.35167,
      str_detect(locationID, "54") ~ 25.34533,
      .default = lat_in
    ),
    
    station = case_when(
      str_detect(locationID, "MR") ~ "Molasses Reef",
      str_detect(locationID, "LK") ~ "Looe Key (deep)",
      str_detect(locationID, "WS") ~ "Western Sambo",
      .default = locationID
    )
    
  ) %>%
  relocate(flowmeter_diff, .after = flowmeter_out) %>%
  relocate(contains("ignore"), .after = last_col()) %>%
  relocate(date_time, date, "time_gmt" = time, .after = mesh_size_um)  %>%
  relocate(station, .before = locationID) %T>%
  print()



```

```{r}
noaa_zoo_metadata %>% 
  filter(str_detect(locationID, "MR|LK|WS")) %>%
  mutate(
      .keep = "used",
      cruise_id,
      locationID,
      year = as.factor(year(date))
  ) %>%
  filter(is.na((year)))
```


```{r plots}
noaa_zoo_metadata %>% 
  filter(str_detect(locationID, "MR|LK|WS")) %>%
  ggplot(aes(x = date, y = volume_filt_cubic_m, color = locationID)) +
  geom_point() +
  facet_grid(cols = vars(locationID), rows = vars(mesh_size_um), scales = "free")


noaa_zoo_metadata %>% 
  filter(str_detect(locationID, "MR|LK|WS")) %>%
  ggplot(aes(x = date, y = volume_filt_cubic_m, color = locationID)) +
  geom_point() +
  facet_grid(cols = vars(locationID), rows = vars(mesh_size_um), scales = "free") +
  scale_y_continuous(limits = c(-100, 1200), expand = expansion())
    
# volume filt <= 0 or > 500   
noaa_zoo_metadata %>%
  filter(str_detect(locationID, "MR|LK|WS")) %>%
  filter(volume_filt_cubic_m <= 0 | volume_filt_cubic_m > 500) %T>%
  print() %>%
  ggplot(aes(x = date, y = volume_filt_cubic_m, color = locationID)) +
  geom_point() +
  facet_grid(cols = vars(locationID), rows = vars(mesh_size_um), scales = "free")  

# tow time vs vol filt
noaa_zoo_metadata %>% 
  filter(str_detect(locationID, "MR|LK|WS")) %>%
  ggplot(aes(x = tow_time_min, y = volume_filt_cubic_m, color = as.factor(year(date)))) +
  geom_point() +
  facet_grid(cols = vars(locationID), rows = vars(mesh_size_um), scales = "free") +
  # scale_y_continuous(limits = c(-100, 1200), expand = expansion()) +
  scale_x_continuous(limits = c(0, NA), expand = expansion(0, c(0, 1))) 

noaa_zoo_metadata %>% 
  filter(str_detect(locationID, "MR|LK|WS")) %>%
  ggplot(aes(x = tow_time_min, y = volume_filt_cubic_m, color = as.factor(year(date)))) +
  geom_point() +
  facet_grid(cols = vars(locationID), rows = vars(mesh_size_um), scales = "free") +
  scale_y_continuous(limits = c(-100, 1000), expand = expansion(0, c(0, 100))) +
  scale_x_continuous(limits = c(0, NA), expand = expansion(0, c(0, 1)), 
                     breaks = seq(0, 8)) 

```




# Save merged NOAA metadata
```{r save}
overwrite <- FALSE
# overwrite <- TRUE

# ---- write metadata to file ----
save_csv(
  .data          = noaa_zoo_metadata,        
  save_location  = here("data", "metadata", "cruise_logsheets"),
  save_name      = "zoo_noaa_meta",
  overwrite      = overwrite,
  verbose        = TRUE,
  time_stamp_fmt = "%Y%m%d_%H%M%S",
  utf_8          = FALSE
)

# copy to cloud
if (FALSE) {
  here("data", "metadata", "cruise_logsheets") %>%
  dir_ls(regexp = "zoo_noaa_meta") %>%
  last_mod() %>% 
  file_copy(
      here(cloud_dir, "cruise_logsheets", "zoo_noaa_meta.csv"),
      overwrite = TRUE
  )
}

```


