---
title: "OBIS Event Creations"
author: "Sebastian DiGeronimo"
date: '2022-09-02'
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---
TODO: check how to save UTF-8 encoding on csv files 
TODO: station depth and uncertainty
TODO: 

# 1.0 Load
## 1.1 Libraries and Calculations

```{r setup}
if (!nzchar(system.file(package = "librarian"))) 
    install.packages("librarian")

librarian::shelf(
    quiet = TRUE,
    librarian, conflicted, ggplot2, tibble, tidyr, readr, purrr, dplyr, stringr,
    forcats, lubridate, glue, fs, magrittr, here,
    
    # additional
    
)

conflicts_prefer(
  dplyr::filter(), 
  dplyr::select()
  )

# library("readxl")
# library("hablar") # might be useful when needing to fix names
# library("worrms")
# library("geosphere")


# obistools::event_fields()
# source(here::here("scripts","log_file_changes.R"))
# startup("log_edits")
# log_add()
```

## 1.2 Other Variables Needed
Only needed identifier. This may be updated for future samples and can filter 
for specific samples.
```{r other-vars}
other_vars <- list()

# ---- recorded by info
other_vars$identifier       <- "Natalia Lopez Figueroa"
other_vars$identifier_orcid <- "https://orcid.org/0000-0002-7527-0481"

other_vars$larval_stage <- 
    tribble(
        # original name  # DwC versions
        ~larva_orig,     ~larva_new,
       "copepodite", "copepodites",
          "nauplii",     "nauplii", 
           "larvae",      "larvae",
           "larva",      "larvae",
         "juvenile",    "juvenile",
             "eggs",         "egg",
              "egg",         "egg",
             "zoea",       "zoeae",
        "protozoea",  "protozoeae",
           "cypris",      "cypris",
         "megalopa",    "megalopae"
    )

```

## 1.3 Load functions, if not already
This will load the functions needed if not already contain in the search path.
```{r load-functions}
source(here("scripts", "attach_funcs.R"))
func_attach()
rm(func_attach)
```
## 1.4 Info on Workflow
Workflow:
<https://github.com/ioos/bio_data_guide/tree/main/OBIS_data_tiers>
3 "Cores": 
   1. Event - where/when took place
   2. Occurrence -  species info, presence/absence 
   3. Measurement or Fact (MoF) - if any, other necessary and environmental 
                                  quantities measured

Steps:
1. Read in previous data
2. Add additional taxonomic information using aphia ID
3. Merge metadata and calculate densities
4. Add columns to convert to DarwinCore
5. Extract each core
  - EventCore
  - OccurrenceCore
  - MoFcore


## 1.5 Load data for OBIS conversion
```{r load-data}
# ---- search file ---- #
dwc_info_path <-
  # here("data", "processed", "pre_obis") %>%
  here(cloud_dir, "processed") %>%
  dir_ls(regexp = "zoo_data_pre_obis") %>%
  last_mod() %T>%
  print()

# ---- load file ---- #
dwc_info <-
  dwc_info_path %>%
  read_csv(
    show_col_types = FALSE,
    guess_max      = 4000
  ) %>%
  left_join(
    other_vars$larval_stage,
    by = c("lifeStage" = "larva_orig")
  ) %>%
  print()
```

## 1.6 Load MoF Base Info
URL for controlled vocab: <http://vocab.nerc.ac.uk/collection/>

```{r mof-base}
# TODO: edit MoF for more information
# source mof file
source(here("scripts", "mof_base_create_table.R"))

mof_info <- list()

# ---- function to create/read base mof info
mof_info$mof_base <-
  mof_read() %T>%
  print() %>%
  filter(!is.na(measurementType))

mof_info$mof_base
```

# 2.0 DarwinCore/OBIS Conversion
## 2.1 Ex: Occurrence Bare Minimum example
set to `TRUE` if want to run
```{r obis-file}
# if (FALSE) {
#    data.table::data.table(
#           occurrenceID = c("my-dataset-0001c29"),
#        decimalLatitude = c(-87.7575),
#       decimalLongitude = c(24.4727),
#         scientificName = c("Sparisoma aurofrenatum"),
#       scientificNameID = c("urn:lsid:ipni.org:names:37829-1:1.3"),
#       occurrenceStatus = c("present"),
#          basisOfRecord = c("HumanObservation"),
#              datasetID = c("my-dataset-tylar-2020-01-08-123456"),
#              eventDate = c("2010-01-03T13:44Z")
#     )
# }
```

## 2.2 Add DarwinCore Columns
Here is where all the information to convert to DarwinCore format is created.
Later the columns will be extracted for each `core`. 

Spelling matters and can be check here: <https://dwc.tdwg.org/terms/>
```{r dwc-cols}
dwc_info <-
  dwc_info %>% 
  mutate(
    rowNumber = row_number(),
    .before   = 1
  ) %>%
 
# ============================================================================ #
# ---- 2.2.1 Record Level ---- #
# ============================================================================ #
  mutate(
    type                   = "Event",
    modified               = format(Sys.Date(), "%Y-%m-%d"),
    language               = "en",
    license                = "http://creativecommons.org/publicdomain/zero/1.0/legalcode",
    institutionCode        = "USF | NOAA", # include NOAA
    # ownerInstitutionCode = "USF",
    collectionCode         = "SEUS-MBON-Zooplankton",
    parentEventID          = "IMaRS_MBON_zooplankton",
    datasetName            = paste(
      "MBON/USF-IMaRS/NOAA AOML Florida Keys National",
      "Marine Sanctuary Zooplankton Net Tows"
    ),
    basisOfRecord          = "PreservedSpecimen", # "HumanObservation",
    recordedBy             = "NOAA AOML | USF IMaRS",
    identifiedBy           = other_vars$identifier  ,
    identifiedByID         = other_vars$identifier_orcid,
  ) %T>%
  print() %>%
    
# ============================================================================ #
# ---- 2.2.2 Event Level ---- #
# ============================================================================ #    
  mutate(
    # catalogNumber = # maybe add in the future
    locationID       = site,
    eventDate        = format_ISO8601(date_time, usetz = "Z"),
    eventID          = glue("{cruise_id}:stn{locationID}:{mesh}um:{date}"),
    # keeping same `eventID` from previous submission
    # cruise ID was updated afterwards
    eventID = str_replace(eventID,  "WS17282", "WS17275"),
    
    fieldNumber      = glue("{cruise_id}-{station}-{mesh}"),
    year             = year(date_time),
    month            = month(date_time),
    day              = day(date_time),
    samplingProtocol = glue(
      "{mesh} mesh size (um) - bongo nets",
      "folson splitter",
      "http://drs.nio.org/drs/handle/2264/95",
      .sep = " | "
    ),

    # TODO: habitat NERC vocab
    habitat          = case_match(
        locationID,
        c("MR", "LK", "WS", "9B") ~ "near coral reef",
        c("57", "54") ~ "near river mouth", 
        .default = NA),
    sampleSizeValue  = volume_filt_cubic_m,
    sampleSizeUnit   = "Volume per cubic metre of filtered seawater",
    samplingEffort   = str_c(tow_time_min, "minutes", sep = " "),
  ) %T>%
  print() %>%

# ============================================================================ #
# ---- 2.2.3 Location Level ---- #
# ============================================================================ #        
  mutate(
    decimalLatitude   = lat_in,
    decimalLongitude  = lon_in,
    higherGeographyID = case_match(
      site,
      c("MR", "LK", "WS", "9B") ~ "http://vocab.getty.edu/tgn/7030258",
      c("57", "54")             ~ "http://vocab.getty.edu/tgn/1101513",
      .default = "Not Found"
    ),
    higherGeography   = "North America | United States | Florida",
    continent         = "North America",
    country           = "United States",
    countryCode       = "US",
    stateProvince     = "Florida",
    geodeticDatum     = "EPSG:4326",
    georeferencedBy   = "NOAA AOML | USF IMaRS | RSMAS R/V Walton Smith",
    georeferenceVerificationStatus = "verified by contributor"
  ) %T>%
  print() %>%
    
# ============================================================================ #
# ---- 2.2.4 Occurrence Level ---- #
# ============================================================================ #    
  mutate(
    lifestage            = larva_new,
    larva_new            = if_else(is.na(larva_new), "unkwn", larva_new),
    # occurrenceID         = glue("{eventID}:{taxa_orig}:{lifeStage}"),
    occurrenceID         = glue("{eventID}:{taxa_orig}:{larva_new}"),
    occurrenceID         = str_replace_all(occurrenceID, "\\s", "_"),
    occurrenceID         = str_replace_all(occurrenceID, "\\.", ""),
    
    # keep `occurrenceID`, while lifeStage is larvae
    occurrenceID         = str_replace(occurrenceID, "Cyphonautes:larvae", "Cyphonautes:unkwn"),
    taxonRank            = rank,
    dateIdentified       = date_analyzed,
     # counts of organisms?
    # IDk which of these is accurate
    # individualCount          = number_ind_sample,
    # add each aliquot as a total count per sample event
    # update on April 17, 2023
    # organismQuantity
    # organismQuantity         = ind_m3,
    # organismQuantityType     = "Individuals per cubic metre",
    # update June 26, 2023
    # change organismQuantity to a density of individuals per cubic meter
    # organismQuantity     = individualCount,
    # organismQuantityType = "Summation of 3x 5mL Aliquots",
    organismQuantity     = ind_m3,
    organismQuantityType = "individuals per cubic metre",
    occurrenceStatus     = "present",
    preparations         = str_c(
      "seawater and 10% formalin before analysis in cod ends",
      "70% ethanol after analysis in vials",
      sep = " | "
    ),
    identificationReferences = "WoRMS",
    verbatimIdentification   = taxa_orig,
    disposition = "in collection"
  ) %T>%
  print() %>%
    
# ============================================================================ #
# ---- 2.2.5 Measurement or Fact Additional Terms ---- #
# ============================================================================ #    
  mutate(
    net_type   = "bongo nets",
    microscopy = "microscopy"
  )

   
    # 
    #     # or
    # measurementType          = "Number per cubic metre",
    # MOF? should also include ind/sample?
    # measurementUnitID        =
    # "http://vocab.nerc.ac.uk/collection/P06/current/UPMM/",
    # MOF?
```

## 2.3 Load Pre-2018 Data 
```{r load-pre-2018}
stations <- c("LK", "MR", "WS")

real_loc <- 
tribble(
 ~locationID, ~lon,  ~lat, ~labs,        
 "MR",        -80.4, 25.0, "64, 200, 500",
 "LK",        -81.4, 24.5, "64, 200, 500",
 "WS",        -81.7, 24.5, "64, 200, 500",
 "54",        -81.2, 25.3, "64 (only)",
 "57",        -81.3, 25.4, "64 (only)")

# TODO: add cloud dir
old_data <- 
    here("data", "zoo_pre_2018", "processed") %>%
    dir_ls(regexp = "occurrences") %>%
    last_mod() %>%
    read_csv(show_col_types = FALSE) %T>% print()

dwc_info <-
    old_data %>%
    select(any_of(names(dwc_info))) %>% 
    mutate(
        # .keep = "used",
        eventDate        = format_ISO8601(eventDate, usetz = "Z"),
        eventID          = str_remove(eventID, "\\}"),
        
        occurrenceID     = str_remove_all(occurrenceID, "\\}|\\."),
        occurrenceID     = stringi::stri_trans_general(occurrenceID, "Latin-ASCII"),
        locationID       = case_when(
            str_detect(eventID, stations[1]) ~ stations[1],
            str_detect(eventID, stations[2]) ~ stations[2],
            str_detect(eventID, stations[3]) ~ stations[3],
            .default = NA
        ),
        decimalLatitude = case_when(
            str_detect(locationID, real_loc$locationID[1]) ~ real_loc$lat[1],
            str_detect(locationID, real_loc$locationID[2]) ~ real_loc$lat[2],
            str_detect(locationID, real_loc$locationID[3]) ~ real_loc$lat[3],
        ),
        decimalLongitude = case_when(
            str_detect(locationID, real_loc$locationID[1]) ~ real_loc$lon[1],
            str_detect(locationID, real_loc$locationID[2]) ~ real_loc$lon[2],
            str_detect(locationID, real_loc$locationID[3]) ~ real_loc$lon[3],
        ),
        identifiedBy = "Jaimie Rojas-Marquez",
        identifiedByID = "https://orcid.org/0009-0009-7318-7180"
    )  %>% 
    
    # TODO: figure out what to do with these duplicates?
    filter(!str_detect(eventID, "2$")) %>%
    bind_rows(., dwc_info) %>%
     mutate(
        # .keep = "used",
        year,
        eventDate1 = as_date(eventDate),
        year = if_else(is.na(year),
                        year(eventDate1),
                        year),
        month = if_else(is.na(month),
                        month(eventDate1),
                        month),
        day = if_else(is.na(day),
                        day(eventDate1),
                        day),
    )  %>%
     mutate(
        across(contains("date") & (is.Date | is.POSIXct), 
               \(x) format_ISO8601(x, usetz = "Z"))
    ) %T>%
  print()
```
```{r}
save_csv(
  .data          = dwc_info,
  save_location  =  here("data", "processed", Sys.Date()),
  save_name      = "zooplankton_erddap",
  # overwrite      = TRUE,           # <-- uncomment to overwrite
  verbose        = TRUE,
  time_stamp_fmt = NULL,
  utf_8          = TRUE
    )

if (FALSE && exists("cloud_dir")) {
# if (TRUE && exists("cloud_dir")) {
  copy_file_name <-
    here("data", "processed") %>%
    dir_ls() %>%
    str_subset("zooplankton_erddap\\.csv")

  dir_create(here(cloud_dir, "processed"))

  file_copy(
    copy_file_name,
    here(cloud_dir, "processed", "obis"),
    FALSE
    # TRUE
  )
}

```



# 3.0 Extract "Cores"
The information from each core will be extracted into it's individual `core` to 
save. The actual column names need to match the ones from section `2.2`. This 
section allows the `user` to add/subtract columns from a specific core as 
needed.

## 3.1 EventCore
```{r event-extract}
event_core <-
  dwc_info %>%
  select(
    type,
    modified,
    license,
    institutionCode,
    datasetName,
    language,
    locationID,
    eventDate,
    eventID,
    fieldNumber,
    year,
    month,
    day,
    samplingProtocol,
    habitat,
    sampleSizeValue,
    sampleSizeUnit,
    samplingEffort,
    decimalLatitude,
    decimalLongitude,
    higherGeographyID,
    higherGeography,
    continent,
    country,
    countryCode,
    stateProvince,
    geodeticDatum,
    georeferencedBy,
    coordinateUncertaintyInMeters,
    minimumDepthInMeters,
    maximumDepthInMeters
  ) %>%
  distinct() %>%
  fill(1:language, .direction = "up") %T>%
    
  # keeping same `eventID` from previous submission
  # cruise ID was updated afterwards
  # mutate(eventID = str_replace(eventID,  "WS17282", "WS17275")) %T>% 
  print()
```

## 3.2 Occurrence Core
```{r occur-extract}
occur_core <-
  dwc_info %>%
  select(
    eventID,
    occurrenceID,
    collectionCode,
    scientificName,
    kingdom:genus, # TODO: check if species column exists
    taxonRank,
    # recorded by
    identifiedBy,
    identifiedByID,
    dateIdentified,
    organismQuantity,
    organismQuantityType,
    lifeStage,
    occurrenceStatus,
    preparations,
    scientificNameID,
    basisOfRecord,
    identificationReferences,
    verbatimIdentification,
    georeferenceVerificationStatus,
    disposition
  )  %>%
  fill(collectionCode, .direction = "up") %T>%
    
  # # keeping same `eventID` from previous submission
  # # cruise ID was updated afterwards
  # mutate(eventID = str_replace(eventID,  "WS17282", "WS17275")) %T>%
  print()
```

## 3.3 Measurement or Fact Core (MoF)

### 3.3.1 Convert MoF

```{r mof-extract}
# ============================================================================ #
# ---- Extract and Convert MoF Event Info ----
# ============================================================================ #    
mof_info$mof_event <-
  dwc_info %>%
  
  # ---- filter for unique eventIDs
  distinct(eventID, .keep_all = TRUE) %>%
    
  # ---- select `event` mof variables    
  select(
    eventID,
    any_of(filter(mof_info$mof_base, str_detect(event_occur, "event"))$orig_term)
  ) %>%

  # ---- convert to long format based on eventID
  pivot_longer(
    cols      = -eventID,
    names_to  = "orig_term",
    values_to = "measurementValue",
    values_transform = list(measurementValue = as.character)
  )

# ============================================================================ #
# ---- Extract and Convert MoF Occurrence Info ----
# ============================================================================ #    
mof_info$mof_occur <-
  dwc_info %>%
  
  # ---- filter for unique eventIDs and occurrenceIDs
  distinct(eventID, occurrenceID, .keep_all = TRUE) %>%
    
  # ---- select `occurrence` mof variables     
  select(
    eventID, occurrenceID,
    any_of(filter(mof_info$mof_base, str_detect(event_occur, "occur"))$orig_term)
  ) %>%

  # ---- convert to long format based on eventID and occurrenceID
  pivot_longer(
    cols      = -c(eventID, occurrenceID),
    names_to  = "orig_term",
    values_to = "measurementValue",
    values_transform = list(measurementValue = as.character)
  ) 

# ============================================================================ #
# ---- Merge Event and Occurrence MoF with MoF Base ----
# ============================================================================ #    
mof_core <-
  bind_rows(
    mof_info$mof_occur,
    mof_info$mof_event
  ) %>%
 left_join(mof_info$mof_base, by = "orig_term") %>%
 arrange(eventID, event_occur) %>%
 select(
     -orig_term,
     -event_occur,
     -measurementAccuracy # maybe will update later
     ) %T>% print()


slice_sample(mof_core, n = 1, by = eventID)
cli::cli_alert_info("Dimensions: {dim(mof_core)}")
```

    # 4.0 Examples to save
```{r dup-check}
janitor::get_dupes(event_core)
janitor::get_dupes(event_core, eventID)
janitor::get_dupes(occur_core)
janitor::get_dupes(occur_core, occurrenceID)
janitor::get_dupes(mof_core) # splits_analyzed and split_size are different, but no definition

occur_core
```
## 4.1 Show Missing Data
```{r}
naniar::vis_miss(event_core)
naniar::vis_miss(occur_core)
naniar::vis_miss(mof_core)
```

## 4.2 Save A Subset of Data, 5 samples
```{r save-subset}
set.seed(1234)
events <- sample(unique(event_core$eventID), 5)

pwalk(
  list(
    list(
      filter(event_core, eventID %in% events),
      filter(occur_core, eventID %in% events),
      filter(mof_core, eventID %in% events)
    ),
    here("data", "processed", "obis_example", Sys.Date()),
    glue("{c(\"event\", \"occur\", \"mof\")}_example_update")
  ),
  \(data, loc, name_f)
    save_csv(
      .data          = data,
      save_location  = loc,
      save_name      = name_f,
      # overwrite      = TRUE,          # <-- uncomment to overwrite
      verbose        = TRUE,
      time_stamp_fmt = "%Y-%m-%d",
      utf_8          = TRUE
    )
)
```

## 4.3 Save All Data
```{r save-full}
pwalk(
  list(
    list(
      event_core,
      occur_core,
      # mof_core
      filter(mof_core, !(is.na(measurementValue)))
    ),
    here("data", "processed", "obis", Sys.Date()),
    glue("{c(\"event\", \"occur\", \"mof\")}")
  ),
  \(data, loc, name_f)
    save_csv(
      .data          = data,
      save_location  = loc,
      save_name      = name_f,
      # overwrite      = TRUE,        # <-- uncomment to overwrite
      verbose        = TRUE,
      time_stamp_fmt = NULL,
      utf_8 = TRUE
    )
)

if (FALSE && exists("cloud_dir")) {
# if (TRUE && exists("cloud_dir")) {
  obis_files <-
    here("data", "processed", "obis") %>%
    dir_ls(type = "file", recurse = 1) %>%
    str_subset("old|ex", negate = TRUE) %>%
    str_subset("2025-02-11") %T>% 
    print()

  dir_create(here(cloud_dir, "processed", "obis"))

  file_copy(
    obis_files,
    here(cloud_dir, "processed", "obis"),
    overwrite = TRUE                 # <-- uncomment to overwrite
  )
}
```


# ---- TEST ----
```{r test}
str_count(occur_core$occurrenceID, "\\.") %>%
    sort(decreasing = T)
occur_core %>%
    filter(str_detect(occurrenceID, "\\.")) %>%
    select(occurrenceID) %>%
    mutate(
        mult = str_count(occurrenceID, "\\."),
        occ2 = str_replace_all(occurrenceID, "\\.", "")
    ) %>%
      filter(mult > 1)

reduce(list(event_core, occur_core, mof_core), left_join) 

left_join(dwc_info,
        mof_core,
        by = c(
            "eventID",
            "occurrenceID"
        )
        ) %>%
          naniar::vis_miss()
    
obistools::report() %>%
    View()

```

```{r}
check_extension_eventids(event_core, mof_core, field = "eventID")


str_subset(obistools::occurrence_fields(), "verbatim")
str_subset(obistools::event_fields(), "")

str_sort(obistools::occurrence_fields())
str_sort(obistools::event_fields())
obistools::event_fields()
obistools::abra %>%
    obistools::report_summary(50)

select(dwc_info, any_of(obistools::occurrence_fields()))

names(rename(occur_core, "disposition" = dispostion)) %in% obistools::occurrence_fields()
# verbatimIdentification


str_subset(names(occur_core), str_c(obistools::occurrence_fields(), collapse = "|"),
           negate = T)
str_subset(names(event_core), str_c(obistools::event_fields(), collapse = "|"),
           negate = T)
```

```{r}
set.seed(1234)
dwc_info %>%
    filter(!is.na(recordedBy)) %>%
    nest(.by = cruise_id) %>%
    slice_sample(n = 2) %>%
    unnest(data) %>%
    slice_head(by = cruise_id, prop = 0.2) %>%
    writexl::write_xlsx(
      here("data", "processed", "obis", "ioos_subsample.xlsx")
        )

shell.exec(here("data", "processed", "obis", "ioos_subsample.xlsx"))
shell.exec(here("data", "processed", "obis"))
```

