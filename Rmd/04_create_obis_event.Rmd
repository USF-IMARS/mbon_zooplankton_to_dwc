---
title: "OBIS Event Creations"
author: "Sebastian DiGeronimo"
date: '2022-09-02'
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---
TODO: check how to save UTF-8 encoding on csv files 
TODO: station depth and uncertainty
TODO: 

# 1.0 Load
## 1.1 Libraries and Calculations
```{r setup}
knitr::opts_chunk$set(echo = TRUE)
librarian::shelf(
    librarian, ggplot2, tibble, tidyr, readr, purrr, dplyr, stringr,
    forcats, lubridate, glue, fs, magrittr, here,
    # broom # optional
    
    # additional
    
)

library("conflicted")

conflicts_prefer(dplyr::filter,
                 dplyr::select)

# library("readxl")
# library("hablar") # might be useful when needing to fix names
# library("worrms")
# library("geosphere")


# obistools::event_fields()
# source(here::here("scripts","log_file_changes.R"))
# startup("log_edits")
# log_add()
```

## 1.2 Other Variables Needed
Only needed identifier. This may be updated for future samples and can filter 
for specific samples.
```{r other-vars}
other_vars <- list()

# ---- recorded by info
other_vars$identifier       <- "Natalia Lopez Figueroa"
other_vars$identifier_orcid <- "https://orcid.org/0000-0002-7527-0481"

```

## 1.3 Load functions, if not already
This will load the functions needed if not already contain in the search path.
```{r load-functions}
source(here("scripts", "attach_funcs.R"))
func_attach()
rm(func_attach)
```
## 1.4 Info on Workflow
Workflow:
<https://github.com/ioos/bio_data_guide/tree/main/OBIS_data_tiers>
3 "Cores": 
   1. Event - where/when took place
   2. Occurrence -  species info, presence/absence 
   3. Measurement or Fact (MoF) - if any, other necessary and environmental 
                                  quantities measured

Steps:
1. Read in previous data
2. Add additional taxonomic information using aphia ID
3. Merge metadata and calculate densities
4. Add columns to convert to DarwinCore
5. Extract each core
  - EventCore
  - OccurenceCore
  - MoFcore


## 1.5 Load data for OBIS conversion
```{r load-data}
taxa_original <- 
    here("data", "processed", "pre_obis")  %>%
    dir_ls(regexp = "zoo_data_pre_obis") %>%
    last_mod() %T>% 
    print()

taxa_original <- 
    taxa_original %>%
    read_csv(show_col_types = FALSE,
             guess_max = 4000)

# ---- ignore ----
# # ---- load aphia id if hasn't previously been
# # TODO: load file from `03_...` for aphia IDs
# 
# aphia_id <-
#     here("data", "metadata") %>%
#     dir_ls(regexp = "aphia_additional")
# 
# if (is_empty(aphia_id) | FALSE) {
#   cli_alert_info("Creating a additional aphia ID file.")
# 
#   # ---- load aphia id
#   aphia_id <-
#     dir_ls(
#       path = here("data", "metadata", "aphia_id"),
#       regexp = "^[^~]*(aphia)+.*\\.csv$"
#     ) %>%
#     last_mod(.) %>%
#     read_csv(show_col_types = FALSE) %>%
#     mutate(
#       aphiaID = str_extract(scientificNameID, "\\d+"),
#       aphiaID = as.numeric(aphiaID),
#       info = map(
#         aphiaID,
#         ~ tryCatch(
#           {
#             worrms::wm_record(.x)
#           },
#           error = function(e) {
#             return(NULL)
#           }
#         )
#       )
#     ) %>%
#     unnest(info, names_repair = janitor::make_clean_names) %>%
#     select(!contains("_2"), -c(2:6))
# 
# 
#   meta_file <-
#     (file_expr(
#       loc = here("data", "metadata"),
#       file_base = "aphia_additional"
#     ))[[2]] %>%
#     eval()
# 
#   cli_alert_info("File name: {.file {basename(meta_file)}}")
# 
#   write_csv(aphia_id,
#     file = meta_file,
#     na   = ""
#   )
# } else {
#   aphia_id <-
#     aphia_id %>%
#     last_mod()
# 
#   cli_alert_info("Loading file: {.file {basename(aphia_id)}}")
# 
#   aphia_id <-
#       read_csv(
#           aphia_id,
#           show_col_types = FALSE
#   )
# }
# 
# # ---- load metadata
# meta_df <-
#     dir_ls(
#         path   = here("data", "metadata", "cruise_logsheets"),
#         regexp = "^[^~]*(meta_)+.*\\.csv$") %>%
#     last_mod(.) %>%
#     read_csv(show_col_types = FALSE) %>%
# 
#     # this is when Natalia LF started analysis
#     filter(date >= date("2017-06-18")) %>%
# 
#     mutate(locationID      = case_when(
#                 str_detect(station, "Mol")  ~ "MR",
#                 str_detect(station, "Loo")  ~ "LK",
#                 str_detect(station, "West") ~ "WS",
#                 str_detect(station, "9B")   ~ "9B",
#                 .default = station),
#            .after = station) %>%
#     mutate(
#         # Note: flowmeter is MF315
#         net_size            = 0.5,
#         net_area            = pi * 0.5^2,
#         distance_m_2        = (flowmeter_out - flowmeter_in) * inpeller_constant,
#         tow_speed_m_sec     = distance_m_2 / (tow_time_min * 60),
#         # tow_speed_cm_sec     = distance_m_2 * 100 / (tow_time_min * 60),
#         volume_filt_cubic_m = net_area/4 * distance_m_2,
#         split_size          = map_dbl(split_size,
#                                       function(x) {
#                                     out <- tryCatch({
#                                     eval(parse(text = x))},
#                                     error = function(e) {NA_integer_})}
#                                     )
#        )
# 
# # ---- load zooplankton data
# taxa_files <-
#     dir_ls(
#         path = here("data", "processed"),
#         regexp = "all_merged_processed") %>%
#     last_mod(.) %>%
#     map_dfr(~ read_csv(., show_col_types = FALSE)) %>%
#     mutate(
#         # ONLY USED IF:
#         # need to fix info from a specific cruise ID
#         # - uncomment and replace "" with the cruise ID and new cruise ID
#         # cruise_id = case_when(
#         #     # str_detect(cruise_id, "") ~ "", # incase other become problematic
#         #     .default = cruise_id
#         #     ),
#         site      = str_replace(site, "MK", "MR"),
#         lifeStage = case_when(
#             is.na(lifeStage) ~ "adult",
#             .default = lifeStage),
#         splits_analyzed = case_when(
#             is.na(splits_analyzed) | splits_analyzed == 0 ~ 1,
#             .default = splits_analyzed
#         )
#     ) %>%
#   select(-mean_ind_dil_factor) %>%
#   rowwise(aliquot_1:aliquot_3) %>%
#   mutate(
#       individualCount = sum(aliquot_1,
#                             aliquot_2,
#                             aliquot_3,
#                             na.rm = TRUE),
#       .before = aliquot_1
#   ) %>%
#   ungroup()
# 
# # ---- merge metadata and taxa data
# taxa_original2 <-
#   taxa_files %>%
#   left_join(
#     meta_df,
#     by = c(
#       "cruise_id",
#       "site" = "locationID",
#       "mesh" = "mesh_size_um"
#     )
#   ) %>%
#   mutate(
#     # split_amount = 0.5, # splits from cruise
#     splits_analyzed = if_else(
#       is.na(splits_analyzed),
#       0,
#       splits_analyzed
#     ),
#     number_ind_sample = eval(other_vars$equation_zoo),
#     ind_m3 = number_ind_sample / volume_filt_cubic_m,
# 
#     # get aphia ID from end of scientificNameID
#     aphiaID = str_extract(scientificNameID, "\\d+"),
#     aphiaID = as.numeric(aphiaID),
# 
#     maximumDepthInMeters = case_when(
#       str_detect(site, "MR") ~ other_vars$max_depth$MR,
#       str_detect(site, "LK") ~ other_vars$max_depth$LK,
#       str_detect(site, "WS") ~ other_vars$max_depth$WS,
#       str_detect(site, "57") ~ other_vars$max_depth$`57`,
#       str_detect(site, "54") ~ other_vars$max_depth$`54`,
#       str_detect(site, "9B") ~ other_vars$max_depth$`9B`
#     ),
#     minimumDepthInMeters = 0,
#     coordinateUncertaintyInMeters = 500
#   ) %>%
#   left_join(.,
#     aphia_id,
#     by = c(
#       "taxa_orig" = "taxa_orig",
#       "aphiaID"   = "aphia_id"
#     )
#   )
```

# 2.0 DarwinCore/OBIS Conversion
## 2.1 Ex: Occurrence Bare Minimum example
set to `TRUE` if want to run
```{r obis-file}
# if (FALSE) {
#    data.table::data.table(
#           occurrenceID = c("my-dataset-0001c29"),
#        decimalLatitude = c(-87.7575),
#       decimalLongitude = c(24.4727),
#         scientificName = c("Sparisoma aurofrenatum"),
#       scientificNameID = c("urn:lsid:ipni.org:names:37829-1:1.3"),
#       occurrenceStatus = c("present"),
#          basisOfRecord = c("HumanObservation"),
#              datasetID = c("my-dataset-tylar-2020-01-08-123456"),
#              eventDate = c("2010-01-03T13:44Z")
#     )
# }
```

## 2.2 Add DarwinCore Columns
```{r dwc-cols}
dwc_info <-
  taxa_original %>% 
  mutate(
    rowNumber = row_number(),
    .before   = 1
  ) %>%
 
# ============================================================================ #
# ---- 2.2.1 Record Level ----
# ============================================================================ #
  mutate(
    type                   = "Event",
    modified               = Sys.Date(),
    language               = "en",
    license                = "http://creativecommons.org/publicdomain/zero/1.0/legalcode",
    institutionCode        = "USF | NOAA", # include NOAA
    # ownerInstitutionCode = "USF",
    colletionCode          = "SEUS-MBON-Zooplankton",
    parentEventID          = "IMaRS_MBON_zooplankton",
    datasetName            = paste(
      "MBON/USF-IMaRS/NOAA AOML Florida Keys National",
      "Marine Sanctuary Zooplankton Net Tows"
    ),
    basisOfRecord          = "PreservedSpecimen", # "HumanObservation",
    recordedBy             = "NOAA AOML",
    identifiedBy           = other_vars$identifier  ,
    identifiedByID         = other_vars$identifier_orcid,
  ) %T>%
  print() %>%
    
# ============================================================================ #
# ---- 2.2.2 Event Level ----
# ============================================================================ #    
  mutate(
    # catalogNumber = # maybe add in the future
    locationID       = site,
    eventDate        = format_ISO8601(date_time, usetz = "Z"),
    eventID          = glue("{cruise_id}:stn{locationID}:{mesh}um:{date}"),
    fieldNumber      = glue("{cruise_id}-{station}-{mesh}"),
    year             = year(date_time),
    month            = month(date_time),
    day              = day(date_time),
    samplingProtocol = glue(
      "{mesh} mesh size (um) - bongo nets",
      "folson splitter",
      "http://drs.nio.org/drs/handle/2264/95",
      .sep = " | "
    ),

    # TODO: habitat NERC vocab
    habitat          = "near reef",
    sampleSizeValue  = volume_filt_cubic_m,
    sampleSizeUnit   = "Volume per cubic metre of filtered seawater",
    samplingEffort   = str_c(tow_time_min, "minutes", sep = " "),
  ) %T>%
  print() %>%

# ============================================================================ #
# ---- 2.2.3 Location Level ----
# ============================================================================ #        
  mutate(
    decimalLatitude   = lat_in,
    decimalLongitude  = lon_in,
    higherGeographyID = case_when(
      str_detect(site, "MR|LK|WS|9B") ~ "http://vocab.getty.edu/tgn/7030258",
      str_detect(site, "5") ~ "http://vocab.getty.edu/tgn/1101513",
      .default = "Not Found"
    ),
    higherGeography   = "North America | United States | Florida",
    continent         = "North America",
    country           = "United States",
    countryCode       = "US",
    stateProvince     = "Florida",
    geodeticDatum     = "EPSG:4326",
    georeferencedBy   = "NOAA AOML | USF IMaRS | RSMAS R/V Walton Smith",
    georeferenceVerificationStatus = "verified by contributor"
  ) %T>%
  print() %>%
    
# ============================================================================ #
# ---- 2.2.4 Occurence Level ----
# ============================================================================ #    
  mutate(
    occurrenceID         = glue("{eventID}:{taxa_orig}:{lifeStage}"),
    taxonRank            = rank,
    dateIdentified       = date_analyzed,
     # counts of organisms?
    # IDk which of these is accurate
    # individualCount          = number_ind_sample,
    # add each aliquot as a total count per sample event
    # update on April 17, 2023
    # individualCount,
    # organismQuantity         = ind_m3,
    # organismQuantityType     = "Individuals per cubic metre",
    organismQuantity     = individualCount,
    organismQuantityType = "Summation of 3x 5mL Aliquots",
    lifeStage,
    occurrenceStatus     = "present",
    preparations         = str_c(
      "10% formalin before analysis",
      "70% ethanol after analysis",
      sep = " | "
    ),
    identificationReferences = "WoRMS",
    verbatimIdentification   = taxa_orig,
    dispostion = "in collection"
  ) %T>%
  print() %>%
    
# ============================================================================ #
# ---- 2.2.5 Measurement or Fact Additional Terms ----
# ============================================================================ #    
  mutate(
    net_type   = "bongo nets",
    microscopy = "microscopy"
  )

   
    # 
    #     # or
    # measurementType          = "Number per cubic metre",
    # MOF? should also include ind/sample?
    # measurementUnitID        =
    # "http://vocab.nerc.ac.uk/collection/P06/current/UPMM/",
    # MOF?
```

# 3.0 Extract "Cores"

## 3.1 EventCore
```{r event-extract}
event_core <-
  dwc_info %>%
  select(
    type,
    modified,
    license,
    institutionCode,
    datasetName,
    language,
    locationID,
    eventDate,
    eventID,
    fieldNumber,
    year,
    month,
    day,
    samplingProtocol,
    habitat,
    sampleSizeValue,
    sampleSizeUnit,
    samplingEffort,
    decimalLatitude,
    decimalLongitude,
    higherGeographyID,
    higherGeography,
    continent,
    country,
    countryCode,
    stateProvince,
    geodeticDatum,
    georeferencedBy,
    coordinateUncertaintyInMeters,
    minimumDepthInMeters,
    maximumDepthInMeters
  ) %>%
  distinct() %T>% 
  print()
```

## 3.2 Occurence Core
```{r occur-extract}
occur_core <-
  dwc_info %>%
  select(
    eventID,
    occurrenceID,
    scientificName,
    kingdom:genus, # TODO: check if species column exists
    taxonRank,
    # recorded by
    identifiedBy,
    identifiedByID,
    dateIdentified,
    organismQuantity,
    organismQuantityType,
    lifeStage,
    occurrenceStatus,
    preparations,
    scientificNameID,
    basisOfRecord,
    identificationReferences,
    verbatimIdentification,
    georeferenceVerificationStatus,
    dispostion
  ) %T>%
  print()
```

## 3.3 Measurement or Fact Core (MoF)
### 3.3.1 MoF Base Info

URL for controlled vocab: "http://vocab.nerc.ac.uk/collection/"

```{r mof-base}
mof_info <- list()

# TODO: edit MoF for more information
# result of script is mof_base variable
source(here("scripts", "mof_base_create_table.R"))
mof_info$mof_base <- mof_read()

mof_info$def_web <- "http://vocab.nerc.ac.uk/collection/"

mof_info$mof_base <-
  mof_info$mof_base %>%
  mutate(
    across(contains("_uri"),
      .fns = ~ if_else(
        !is.na(.x),
        str_c(mof_info$def_web, .),
        NA_character_
      )
    )
  ) %>%
  rename(
    "measurementTypeID" = measurementType_uri,
    "measurementUnitID" = measurementUnit_uri
  ) %>%
  select(-measurementValue)

mof_info$mof_base
```


### 3.3.2 Convert MoF
```{r mof-extract}
# ============================================================================ #
# ---- MoF Event Info ----
# ============================================================================ #    
mof_info$mof_event <-
  dwc_info %>%
  distinct(eventID, .keep_all = TRUE) %>%
  select(
    eventID,
    filter(mof_info$mof_base, str_detect(event_occur, "event"))$orig_term
  ) %>%
  pivot_longer(
    cols      = -eventID,
    names_to  = "orig_term",
    values_to = "measurementValue",
    values_transform = list(measurementValue = as.character)
  ) %>%
  left_join(mof_info$mof_base, by = "orig_term")

# ============================================================================ #
# ---- MoF Occurrence Info ----
# ============================================================================ #    
mof_info$mof_occur <-
  dwc_info %>%
  distinct(eventID, occurrenceID, .keep_all = TRUE) %>%
  select(
    eventID, occurrenceID,
    filter(mof_info$mof_base, str_detect(event_occur, "occur"))$orig_term
  ) %>%
  pivot_longer(
    cols      = -c(eventID, occurrenceID),
    names_to  = "orig_term",
    values_to = "measurementValue",
    values_transform = list(measurementValue = as.character)
  ) %>%
  left_join(mof_info$mof_base, by = "orig_term")

mof_info$mof_core <-
  bind_rows(
    mof_info$mof_occur,
    mof_info$mof_event
  ) %>%
 select(-orig_term, -event_occur)

slice_sample(mof_info$mof_core, n = 1, by = eventID)
cli::cli_alert_info("Dimensions: {dim(mof_info$mof_core)}")
```



# 4.0 Examples to save
```{r save}
set.seed(1234)

walk2(
    .x = glue("{c('event', 'occur', 'mof')}_example_update"), 
    .y = list(event_core, occur_core, mof_info$mof_core),
    ~ save_csv(
    .data         = .y,
    save_location = here("data", "processed", "obis_example", Sys.Date()),
    save_name     = .x,
    overwrite     = FALSE,
    verbose       = TRUE,
    time_stamp_fmt = "%Y-%m-%d"
    )
)
```


# TEST
```{r test}
reduce(list(event_core, occur_core, mof_core), left_join) %>%
    obistools::check_depth(.)

dwc_info %>%
    select(scientificName, aphiaID) %>%
    slice_head(n = 10) %>%
    mutate(
        .keep = "none",
        scientificName,
    info = map(aphiaID, ~ worrms::wm_record(.x))
) %>%
  unnest(info)

reduce(list(event_core, occur_core), left_join) %>%
    # names() 

obistools::report() %>%
    View()


obistools::event_fields()
```

