---
title: "OBIS Event Creations"
author: "Sebastian DiGeronimo"
date: '2022-09-02'
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---
TODO: check how to save UTF-8 encoding on csv files 
TODO: station depth and uncertainty
TODO: 

# 1.0 Load
## 1.1 Libraries and Calculations
```{r setup}
knitr::opts_chunk$set(echo = TRUE)
librarian::shelf(
    librarian, ggplot2, tibble, tidyr, readr, purrr, dplyr, stringr,
    forcats, lubridate, glue, fs, magrittr, here,
    # broom # optional
    
    # additional
    
)

library("conflicted")

conflicts_prefer(dplyr::filter,
                dplyr::select)

# library("readxl")
# library("hablar") # might be useful when needing to fix names
# library("worrms")
# library("geosphere")


# obistools::event_fields()
# source(here::here("scripts","log_file_changes.R"))
# startup("log_edits")
# log_add()
```

## 1.2 Other Variables Needed
```{r other-vars}
other_vars <- list()

# ---- recorded by info
other_vars$identifier       <- "Natalia Lopez Figueroa"
other_vars$identifier_orcid <- "https://orcid.org/0000-0002-7527-0481"

# ---- max depth per site
other_vars$max_depth <-
  list(
    "MR" = 36.5,
    "LK" = 40.5,
    "WS" = 23,
    "54" = 3,
    "57" = 5,
    "9B" = 31
  )

# ---- set variables for calculation
other_vars$inpeller <- 26873 / 999999 # starting oct 2022 for 200/500 um
# net_area <- pi * 0.5^2

# Note: jamie dillution / pippete_vol_m_l is the same as nat dillution_factor
# 
# total num individual (sum all aliquots)  * vol sample water (known vol) / counted aliquot * split size / folson (mL per aliquot)
# 
# 
# mean = total num / counted aliquots 
# dilution factor = vol sample water / folson 
# 
which_one <- "nat"
other_vars$equation_zoo <- switch(
    which_one,
    "nat"    = expression(dillution_factor * mean * 2 ^ (splits_analyzed)),
    "nat2"   = expression(dillution_factor * mean * (splits_analyzed * split_size)^-1),
    "nat3"   = expression(dillution_factor * mean * (splits_analyzed)^-1),
    "jamie"  = expression((dillution / pipette_vol_m_l) * mean * splits_analyzed ),
    "jamie2" = expression(dillution * mean)
)
rm(which_one)
```

## 1.3 Load functions, if not already
This will load the functions needed if not already contain in the search path.
```{r load-functions}
source(here("scripts", "attach_funcs.R"))
func_attach()
rm(func_attach)
```
## 1.4 Info on Workflow
Workflow:
<https://github.com/ioos/bio_data_guide/tree/main/OBIS_data_tiers>
3 "Cores": 
   1. Event - where/when took place
   2. Occurrence -  species info, presence/absence 
   3. Measurement or Fact (MoF) - if any, other necessary and environmental 
                                  quantities measured

Steps:
1. Read in previous data
2. Add additional taxonomic information using aphia ID
3. Merge metadata and calculate densities
4. Add columns to convert to DarwinCore
5. Extract each core
  - EventCore
  - OccurenceCore
  - MoFcore


## 1.5 Load data for OBIS conversion
```{r load-data}
# ---- load aphia id if hasn't previously been
# TODO: load file from `03_...` for aphia IDs
if (!exists("aphia_id")) {
  aphia_id <-
    dir_ls(
      path   = here("data", "metadata", "aphia_id"),
      regexp = "^[^~]*(aphia)+.*\\.csv$"
    ) %>%
    last_mod(.) %>%
    read_csv(show_col_types = FALSE) %>%
    mutate(
      aphiaID = str_extract(scientificNameID, "\\d+"),
      aphiaID = as.numeric(aphiaID),
      info = map(
        aphiaID,
        ~ tryCatch(
          {
            worrms::wm_record(.x)
          },
          error = function(e) {
            return(NULL)
          }
        )
      )
    ) %>%
    unnest(info, names_repair = janitor::make_clean_names) %>%
    select(!contains("_2"), -c(2:6))
}

# ---- load metadata
meta_df <-
    dir_ls(
        path   = here("data", "metadata", "cruise_logsheets"),
        regexp = "^[^~]*(meta_)+.*\\.csv$") %>%
    last_mod(.) %>%
    read_csv(show_col_types = FALSE) %>%
    
    # this is when Natalia LF started analysis
    filter(date >= date("2017-06-18")) %>%
    
    mutate(locationID      = case_when(
                str_detect(station, "Mol")  ~ "MR",
                str_detect(station, "Loo")  ~ "LK",
                str_detect(station, "West") ~ "WS",
                str_detect(station, "9B")   ~ "9B",
                .default = station), 
           .after = station) %>%
    mutate(
        # Note: flowmeter is MF315
        net_size            = 0.5,
        net_area            = pi * 0.5^2,
        distance_m_2        = (flowmeter_out - flowmeter_in) * inpeller_constant,
        tow_speed_m_sec     = distance_m_2 / (tow_time_min * 60),
        # tow_speed_cm_sec     = distance_m_2 * 100 / (tow_time_min * 60),
        volume_filt_cubic_m = net_area/4 * distance_m_2,
        split_size          = map_dbl(split_size, 
                                      function(x) {
                                    out <- tryCatch({
                                    eval(parse(text = x))}, 
                                    error = function(e) {NA_integer_})}
                                    ) 
       ) 

# ---- load zooplankton data
taxa_files <-
    dir_ls(
        path = here("data", "processed"),
        regexp = "all_merged_processed") %>%
    last_mod(.) %>%
    map_dfr(~ read_csv(., show_col_types = FALSE)) %>%
    mutate(
        # ONLY USED IF:
        # need to fix info from a specific cruise ID
        # - uncomment and replace "" with the cruise ID and new cruise ID
        # cruise_id = case_when(
        #     # str_detect(cruise_id, "") ~ "", # incase other become problematic
        #     .default = cruise_id
        #     ),
        site      = str_replace(site, "MK", "MR"),
        lifeStage = case_when(
            is.na(lifeStage) ~ "adult",
            .default = lifeStage),
        splits_analyzed = case_when(
            is.na(splits_analyzed) | splits_analyzed == 0 ~ 1,
            .default = splits_analyzed
        )
    ) %>%
  select(-mean_ind_dil_factor) %>%
  rowwise(aliquot_1:aliquot_3) %>%
  mutate(
      individualCount = sum(aliquot_1, 
                            aliquot_2, 
                            aliquot_3, 
                            na.rm = TRUE),
      .before = aliquot_1
  ) %>%
  ungroup()

# ---- merge metadata and taxa data
taxa_original <-
  taxa_files %>%
  left_join(
    meta_df,
    by = c(
      "cruise_id",
      "site" = "locationID",
      "mesh" = "mesh_size_um"
    )
  ) %>%
  mutate(
    # split_amount = 0.5, # splits from cruise
    splits_analyzed = if_else(
      is.na(splits_analyzed), 
      0,
      splits_analyzed
    ),
    number_ind_sample = eval(other_vars$equation_zoo),
    ind_m3 = number_ind_sample / volume_filt_cubic_m,

    # get aphia ID from end of scientificNameID
    aphiaID = str_extract(scientificNameID, "\\d+"),
    aphiaID = as.numeric(aphiaID),
    
    maximumDepthInMeters = case_when(
      str_detect(site, "MR") ~ other_vars$max_depth$MR,
      str_detect(site, "LK") ~ other_vars$max_depth$LK,
      str_detect(site, "WS") ~ other_vars$max_depth$WS,
      str_detect(site, "57") ~ other_vars$max_depth$`57`,
      str_detect(site, "54") ~ other_vars$max_depth$`54`,
      str_detect(site, "9B") ~ other_vars$max_depth$`9B`
    ),
    minimumDepthInMeters = 0,
    coordinateUncertaintyInMeters = 500
  ) %>%
  left_join(.,
    aphia_id,
    by = c(
      "taxa_orig" = "taxa_orig",
      "aphiaID"   = "aphia_id"
    )
  )
```

# 2.0 DarwinCore/OBIS Conversion
## 2.1 Ex: Occurrence Bare Minimum example
set to `TRUE` if want to run
```{r obis-file}
# if (FALSE) {
#    data.table::data.table(
#           occurrenceID = c("my-dataset-0001c29"),
#        decimalLatitude = c(-87.7575),
#       decimalLongitude = c(24.4727),
#         scientificName = c("Sparisoma aurofrenatum"),
#       scientificNameID = c("urn:lsid:ipni.org:names:37829-1:1.3"),
#       occurrenceStatus = c("present"),
#          basisOfRecord = c("HumanObservation"),
#              datasetID = c("my-dataset-tylar-2020-01-08-123456"),
#              eventDate = c("2010-01-03T13:44Z")
#     )
# }
```

## 2.2 Add DarwinCore Columns
```{r dwc-cols}
dwc_info <-
  taxa_original %>% 
  mutate(
    rowNumber = row_number(),
    .before   = 1
  ) %>%
 
# ============================================================================ #
# ---- 2.2.1 Record Level ----
# ============================================================================ #
  mutate(
    type                   = "Event",
    modified               = Sys.Date(),
    language               = "en",
    license                = "http://creativecommons.org/publicdomain/zero/1.0/legalcode",
    institutionCode        = "USF | NOAA", # include NOAA
    # ownerInstitutionCode = "USF",
    colletionCode          = "SEUS-MBON-Zooplankton",
    parentEventID          = "IMaRS_MBON_zooplankton",
    datasetName            = paste(
      "MBON/USF-IMaRS/NOAA AOML Florida Keys National",
      "Marine Sanctuary Zooplankton Net Tows"
    ),
    basisOfRecord          = "PreservedSpecimen", # "HumanObservation",
    recordedBy             = "NOAA AOML",
    identifiedBy           = other_vars$identifier  ,
    identifiedByID         = other_vars$identifier_orcid,
  ) %T>%
  print() %>%
    
# ============================================================================ #
# ---- 2.2.2 Event Level ----
# ============================================================================ #    
  mutate(
    # catalogNumber = # maybe add in the future
    locationID       = site,
    eventDate        = format_ISO8601(date_time, usetz = "Z"),
    eventID          = glue("{cruise_id}:stn{locationID}:{mesh}um:{date}"),
    fieldNumber      = glue("{cruise_id}-{station}-{mesh}"),
    year             = year(date_time),
    month            = month(date_time),
    day              = day(date_time),
    samplingProtocol = glue(
      "{mesh} mesh size (um) - bongo nets",
      "folson splitter",
      "http://drs.nio.org/drs/handle/2264/95",
      .sep = " | "
    ),

    # TODO: habitat NERC vocab
    habitat          = "near reef",
    sampleSizeValue  = volume_filt_cubic_m,
    sampleSizeUnit   = "Volume per cubic metre of filtered seawater",
    samplingEffort   = str_c(tow_time_min, "minutes", sep = " "),
  ) %T>%
  print() %>%

# ============================================================================ #
# ---- 2.2.3 Location Level ----
# ============================================================================ #        
  mutate(
    decimalLatitude   = lat_in,
    decimalLongitude  = lon_in,
    higherGeographyID = case_when(
      str_detect(site, "MR|LK|WS|9B") ~ "http://vocab.getty.edu/tgn/7030258",
      str_detect(site, "5") ~ "http://vocab.getty.edu/tgn/1101513",
      .default = "Not Found"
    ),
    higherGeography   = "North America | United States | Florida",
    continent         = "North America",
    country           = "United States",
    countryCode       = "US",
    stateProvince     = "Florida",
    geodeticDatum     = "EPSG:4326",
    georeferencedBy   = "NOAA AOML | USF IMaRS | RSMAS R/V Walton Smith",
    georeferenceVerificationStatus = "verified by contributor"
  ) %T>%
  print() %>%
    
# ============================================================================ #
# ---- 2.2.4 Occurence Level ----
# ============================================================================ #    
  mutate(
    occurrenceID         = glue("{eventID}:{taxa_orig}:{lifeStage}"),
    taxonRank            = rank,
    dateIdentified       = date_analyzed,
     # counts of organisms?
    # IDk which of these is accurate
    # individualCount          = number_ind_sample,
    # add each aliquot as a total count per sample event
    # update on April 17, 2023
    # individualCount,
    # organismQuantity         = ind_m3,
    # organismQuantityType     = "Individuals per cubic metre",
    organismQuantity     = individualCount,
    organismQuantityType = "Summation of 3x 5mL Aliquots",
    lifeStage,
    occurrenceStatus     = "present",
    preparations         = str_c(
      "10% formalin before analysis",
      "70% ethanol after analysis",
      sep = " | "
    ),
    identificationReferences = "WoRMS",
    verbatimIdentification   = taxa_orig,
    dispostion = "in collection"
  ) %T>%
  print() %>%
    
# ============================================================================ #
# ---- 2.2.5 Measurement or Fact Additional Terms ----
# ============================================================================ #    
  mutate(
    net_type   = "bongo nets",
    microscopy = "microscopy"
  )

   
    # 
    #     # or
    # measurementType          = "Number per cubic metre",
    # MOF? should also include ind/sample?
    # measurementUnitID        =
    # "http://vocab.nerc.ac.uk/collection/P06/current/UPMM/",
    # MOF?
```

# 3.0 Extract "Cores"

## 3.1 EventCore
```{r event-extract}
event_core <-
  dwc_info %>%
  select(
    type,
    modified,
    license,
    institutionCode,
    datasetName,
    language,
    locationID,
    eventDate,
    eventID,
    fieldNumber,
    year,
    month,
    day,
    samplingProtocol,
    habitat,
    sampleSizeValue,
    sampleSizeUnit,
    samplingEffort,
    decimalLatitude,
    decimalLongitude,
    higherGeographyID,
    higherGeography,
    continent,
    country,
    countryCode,
    stateProvince,
    geodeticDatum,
    georeferencedBy,
    coordinateUncertaintyInMeters,
    minimumDepthInMeters,
    maximumDepthInMeters
  ) %>%
  distinct() %T>% 
  print()
```

## 3.2 Occurence Core
```{r occur-extract}
occur_core <-
  dwc_info %>%
  select(
    eventID,
    occurrenceID,
    scientificName,
    across(kingdom:genus), # TODO: check if species column exists
    taxonRank,
    # recorded by
    identifiedBy,
    identifiedByID,
    dateIdentified,
    organismQuantity,
    organismQuantityType,
    lifeStage,
    occurrenceStatus,
    preparations,
    scientificNameID,
    basisOfRecord,
    identificationReferences,
    verbatimIdentification,
    georeferenceVerificationStatus,
    dispostion
  ) %T>%
  print()
```

## 3.3 Measurement or Fact Core (MoF)
### 3.3.1 MoF Base Info

URL for controlled vocab: "http://vocab.nerc.ac.uk/collection/"

```{r mof-base}
# TODO: edit MoF for more information
# result of script is mof_base variable
source(here("scripts", "mof_base_create_table.R"))
mof_base <- mof_read()

def_web <- "http://vocab.nerc.ac.uk/collection/"

mof_base <-
  mof_base %>%
  mutate(
    across(contains("_uri"),
      .fns = ~ if_else(
        !is.na(.x),
        str_c(def_web, .),
        NA_character_
      )
    )
  ) %>%
  rename(
    "measurementTypeID" = measurementType_uri,
    "measurementUnitID" = measurementUnit_uri
  ) %>%
  select(-measurementValue)

mof_base
```


### 3.3.2 Convert MoF
```{r mof-extract}
# ============================================================================ #
# ---- MoF Event Info ----
# ============================================================================ #    
mof_event <-
  dwc_info %>%
  distinct(eventID, .keep_all = TRUE) %>%
  select(
    eventID,
    filter(mof_base, str_detect(event_occur, "event"))$orig_term
  ) %>%
  pivot_longer(
    cols      = -eventID,
    names_to  = "orig_term",
    values_to = "measurementValue",
    values_transform = list(measurementValue = as.character)
  ) %>%
  left_join(mof_base, by = "orig_term")

# ============================================================================ #
# ---- MoF Occurrence Info ----
# ============================================================================ #    
mof_occur <-
  dwc_info %>%
  distinct(eventID, occurrenceID, .keep_all = TRUE) %>%
  select(
    eventID, occurrenceID,
    filter(mof_base, str_detect(event_occur, "occur"))$orig_term
  ) %>%
  pivot_longer(
    cols      = -c(eventID, occurrenceID),
    names_to  = "orig_term",
    values_to = "measurementValue",
    values_transform = list(measurementValue = as.character)
  ) %>%
  left_join(mof_base, by = "orig_term")

mof_core <-
  bind_rows(
    mof_occur,
    mof_event
  ) %>%
 select(-orig_term, -event_occur)
```



# 4.0 Examples to save
```{r save}
if (FALSE) {
  set.seed(1234)
  dir_out <- here("data", "processed", "obis_example")
  path_out <-
    here(
      dir_out,
      glue(
        "{c('event', 'occur', 'mof')}",
        "_example_update_{Sys.Date()}.csv"
      )
    )
  path_out

  dir_create(dir)

  events <- sample(unique(event_core$eventID), 5)

  event_core %>%
    filter(eventID %in% events) %>%
    write_csv(file = path_out[1], na = "")

  occur_core %>%
    filter(eventID %in% events) %>%
    write_csv(file = path_out[2], na = "")

  mof_core %>%
    filter(eventID %in% events) %>%
    write_csv(file = path_out[3], na = "")
}
```


# TEST
```{r test}
reduce(list(event_core, occur_core, mof_core), left_join) %>%
    obistools::check_depth(.)

dwc_info %>%
    select(scientificName, aphiaID) %>%
    slice_head(n = 10) %>%
    mutate(
        .keep = "none",
        scientificName,
    info = map(aphiaID, ~ worrms::wm_record(.x))
) %>%
  unnest(info)

reduce(list(event_core, occur_core), left_join) %>%
    # names() 

obistools::report() %>%
    View()


obistools::event_fields()
```

