---
title: "Merge Metadata, Ocurrence and AphiaID"
author: "Sebastian DiGeronimo"
date: "2023-03-07"
output: html_document
---

TODO: check how to save UTF-8 encoding on csv files 
```{r setup}
librarian::shelf(
    librarian, conflicted, ggplot2, tibble, tidyr, readr, purrr, dplyr, stringr,
    forcats, lubridate, glue, fs, magrittr, here,
    
    # additional
    openxlsx
)

conflicts_prefer(
  dplyr::filter,
  dplyr::select
  )

# obistools::event_fields()
# source(here::here("scripts","log_file_changes.R"))
# startup("log_edits")
# log_add()
```

```{r other-vars}
other_vars <- list()

# ---- recorded by info
other_vars$identifier       <- "Natalia Lopez Figueroa"
other_vars$identifier_orcid <- "https://orcid.org/0000-0002-7527-0481"

# ---- max depth per site
other_vars$max_depth <-
  tribble(
    ~site, ~maximumDepthInMeters,
     "MR",                  36.5,
     "LK",                  40.5,
     "WS",                    23,
     "54",                     3,
     "57",                     5,
     "9B",                    31
  )

# ---- set variables for calculation
other_vars$inpeller <- 26873 / 999999 # starting oct 2022 for 200/500 um
# net_area <- pi * 0.5^2

# Note: jamie dillution / pippete_vol_m_l is the same as nat dillution_factor
# 
# total num individual (sum all aliquots)  * vol sample water (known vol) / counted aliquot * split size / folson (mL per aliquot)
# 
# 
# mean = total num / counted aliquots 
# dilution factor = vol sample water / folson 
# 
which_one <- "nat"
other_vars$equation_zoo <- switch(
    which_one,
    # pretty sure it's `nat`
    "nat"    = expression(dillution_factor * mean * total_split_amount),
    
    
    "nat_old" = expression(dillution_factor * mean * splits_analyzed),
    "nat2"   = expression(dillution_factor * mean * (splits_analyzed * split_size)^-1),
    "nat3"   = expression(dillution_factor * mean * (splits_analyzed)^-1),
    "jamie"  = expression((dillution / pipette_vol_m_l) * mean * splits_analyzed ),
    "jamie2" = expression(dillution * mean)
)
rm(which_one)
```


# Load functions if not already
This will load the functions needed if not already contain in the search path.
```{r load-functions}
source(here("scripts", "attach_funcs.R"))
func_attach()
rm(func_attach)
```

# Load data for OBIS conversion

## Aphia ID Information

Taxonomic information from WoRRMS

```{r load-data}
aphia_id <-
  here("data", "metadata") %>%
  dir_ls(
    regexp = "aphia_extended_info",
    recurse = 1
  )

if (is_empty(aphia_id) | FALSE) {
  cli_alert_info("Creating a additional aphia ID file.")

  # ---- load aphia ID ---- #
  aphia_id <-
    dir_ls(
      path = here("data", "metadata", "aphia_id"),
      regexp = "^[^~]*(aphia)+.*\\.csv$"
    ) %>%
    last_mod(.) %>%
    read_csv(show_col_types = FALSE) %>%
    mutate(
      aphiaID = str_extract(scientificNameID, "\\d+"),
      aphiaID = as.numeric(aphiaID),
      info = pmap(
        list(
          aphiaID,
          taxa_orig,
          row_number()
        ),
        .f = worrms_info_extract # function in taxa_list_check.R
      )
    ) %>%
    unnest(info, names_repair = janitor::make_clean_names) %>%
    select(!contains("_2"), -c(2:6))

  cli_alert_info("\n\nSaving another `Aphia Extended` file!\n}")
  save_csv(
    .data         = aphia_id,
    save_location = here("data", "metadata", "aphia_extended"),
    save_name     = "aphia_extended_info",
    overwrite     = TRUE,
    verbose       = TRUE,
    utf_8         = TRUE
  )

  rm(meta_file)
} else {
  aphia_id <-
    aphia_id %>%
    last_mod()

  cli_alert_info("Loading file: {.file {basename(aphia_id)}}")

  aphia_id <-
    read_csv(
      aphia_id,
      show_col_types = FALSE
    )
}
```

## Load Metadata and Microscopy Data

```{r load-data}
# ---- load metadata ---- #
meta_df <-
  here(cloud_dir, "cruise_logsheets") %>%
  dir_ls(regexp = "^[^~]*(meta_)+.*\\.csv$") %>%
  last_mod(.) %>%
  read_csv(show_col_types = FALSE) %>%
    
  # this is when Natalia LF started analysis
  filter(date >= date("2017-06-18")) %T>% 
  print()

# ---- load zooplankton data ---- #
taxa_files <-
  dir_ls(
    path = here("data", "processed"),
    regexp = "all_merged_processed"
  ) %>%
  last_mod(.) %>%
  map(~ read_csv(., show_col_types = FALSE)) %>%
  list_c() %>%
  mutate(
    site      = str_replace(site, "MK", "MR"),
    cruise_id = str_replace(cruise_id, "WS17275", "WS17282")
  ) %>%
  select(-mean_ind_dil_factor, -lifestage) %>%
  rowwise(aliquot_1:aliquot_3) %>%
  mutate(
    individualCount =
      sum(
        aliquot_1,
        aliquot_2,
        aliquot_3,
        na.rm = TRUE
      ),
    .before = aliquot_1
  ) %>%
  ungroup() %T>%
  print()
```


# Merge Data

Merge:
- metadata
- microscopy data
- taxonomic information

```{r merge-metadata-microscopy-aphiaid}
# ---- merge metadata and taxa data ---- #
taxa_original <-
  taxa_files %>%
  left_join(
    meta_df,
    by = c(
      "cruise_id",
      "site" = "locationID",
      "mesh" = "mesh_size_um"
    )
  ) %>%
  
  rename(
    "ignore_date_collected" = date_collected,
    # "duplicate_mesh_col" = mesh,
    "ignore_filtered_volume_m3" = filtered_volume_m3,
    "file_metadta" = file
  ) %>%
      
    
  # add max depth
  left_join(other_vars$max_depth) %>%

  mutate(
    # add min depth and uncertainty
    minimumDepthInMeters          = 0,
    coordinateUncertaintyInMeters = 500,
    
    # calc the amount of splits of a sample as a whole number to multiply
    # with average and dilution factor
    split_amount       = if_else(is.na(split_amount), 0, split_amount),
    total_split_amount = 2^split_amount * split_size^-1, # whole number
    total_split_frac   = total_split_amount^-1,
     
    number_ind_sample  = eval(other_vars$equation_zoo),
    ind_m3             = number_ind_sample / volume_filt_cubic_m,

    # get aphia ID from end of scientificNameID
    aphiaID = str_extract(scientificNameID, "\\d+"),
    aphiaID = as.numeric(aphiaID)
  ) %>%
  relocate(
    .after = 1,
    site, station:volume_filt_cubic_m, maximumDepthInMeters:total_split_frac) %>%
  relocate(contains(c("ignore", "duplicate")), .after = last_col()) %T>% 
  print() %>%
  left_join(.,
    aphia_id,
    by = c(
      "taxa_orig" = "taxa_orig",
      "aphiaID"   = "aphia_id"
    )
  ) %T>% 
  print()
```
# ---- TODO: relocate metadata to front of data

```{r}
visdat::vis_miss(taxa_original)
```



# Save Merged Data
```{r save-data}
save_csv(
    .data         = taxa_original,
    save_location = here("data", "processed", "pre_obis"),
    save_name     = "zoo_data_pre_obis_merg",
    # overwrite     = TRUE, # comment in to overwrite
    verbose       = TRUE
)

if (FALSE && exists(cloud_dir)) {
  here("data", "processed", "pre_obis") %>%
  dir_ls() %>%
  last_mod() %>%
  file_copy(
      path = .,
      new_path  = here(cloud_dir, "processed", "zoo_data_pre_obis_merg.csv"),
      overwrite = TRUE
    )
}
```

# STOP HERE ------------------

# Create data sheet for Enrique Montes
```{r}
taxa_original %>%
    names()

temp <-
    taxa_original %>%
    mutate(
        key = glue("{cruise_id}:{site}:{mesh}"),
        .before = 1
    ) %>%
    arrange(date_time)
    
meta <- 
    temp %>%
    select(key, cruise_id, site, mesh, date_time,
           lon_in, lat_in, volume_filt_cubic_m) %>%
    distinct()
    
dat <- 
    temp %>%
    select(key, taxa_orig, scientificName, aphiaID, lifeStage, ind_m3, 
           number_ind_sample)
```

```{r}

wb <-
  createWorkbook(
    creator = "Sebastian Di Geronimo",
    title   = "South Florida Zooplankton Net Tows"
  )

# add sheets
addWorksheet(
  wb        = wb,
  sheetName = "metadata"
)

addWorksheet(
  wb        = wb,
  sheetName = "abundances"
)

# add data to sheets
writeData(
  wb    = wb,
  sheet = "metadata",
  x     = meta
)

writeData(
  wb    = wb,
  sheet = "abundances",
  x     = dat
)

openXL(wb)
```

```{r}
dir_create(here("data", "processed", "merged"))
merged_file <- 
    file_expr(loc = here("data", "processed", "merged"),
              file_base = "zooplankton_fl_keys",
              exts = "xlsx")[[2]]
if (FALSE) {
    saveWorkbook(wb,
                 file = eval(merged_file))
} else {
    cli::cli_alert_warning("Not saving final workbook!")
}
```

```{r}
meta <- 
    here(cloud_dir, "cruise_logsheets") %>%
    dir_ls(type = "file") %>%
    last_mod() %>%
    read_csv(show_col_types = FALSE) %>%
    
    mutate(locationID      = case_when(
                str_detect(station, "Mol")  ~ "MR",
                str_detect(station, "Loo")  ~ "LK",
                str_detect(station, "West") ~ "WS",
                str_detect(station, "9B")   ~ "9B",
                .default = station), 
           .after = station)

dat <- 
    here(cloud_dir, "processed") %>%
    dir_ls(type = "file") %>%
    last_mod() %>%
    read_csv(show_col_types = FALSE)


merged_master <- 
    left_join(dat, 
          meta, 
          by = join_by(cruise_id, 
                       site == locationID, 
                       mesh == mesh_size_um))

naniar::gg_miss_case(merged_master)
```

